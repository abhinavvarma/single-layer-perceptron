Conducted following combinations of experiments keeping num_train=500, num_test=250 and epsilon=0.2:

Learn nested boolean function with perceptron update rule:
    1. On boolean distribution data
        a. relu as activation function
            Result:
                Total error : 28
                average error : 0.112
                epsilon :  0.2
                Training success
        b. tanh as activation function
            Result:
                Total error : 0
                average error : 0.0
                epsilon :  0.2
                Training success
        c. threshold as activation function
            Result:
                Total error : 52
                average error : 0.208
                epsilon :  0.2
                Training fail

            Note: When you increase the num_train=750, the error rate dropped.
                Total error : 42
                average error : 0.168
                epsilon :  0.2
                Training success

Learn linear threshold function with perceptron update rule:
    1. On boolean distribution data
        a. relu as activation function
            Result:
                Total error : 0
                average error : 0.0
                epsilon :  0.2
                Training success
        b. tanh as activation function
            Result:
                Total error : 0
                average error : 0.0
                epsilon :  0.2
                Training success
        c. threshold as activation function
            Result:
                Total error : 89
                average error : 0.356
                epsilon :  0.2
                Training fail

            Note : Conducted experiments with different input and output sizes. Still the average error
            rate is nearly the same.

    2. On unit spherical distribution data
        a. relu as activation function
            Result:
                Total error : 47
                average error : 0.188
                epsilon :  0.2
                Training success
        b. tanh as activation function
            Result:
                Total error : 14
                average error : 0.056
                epsilon :  0.2
                Training success
        c. threshold as activation function
            Result:
                Total error : 16
                average error : 0.064
                epsilon :  0.2
                Training success


Comments:
The Perceptron rule was not able to PAC-Learn linear threshold functions under uniform boolean distribution.
They thus match with the PAC learning results learnt from class