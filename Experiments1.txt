Conducted following combinations of experiments keeping num_train=500, num_test=250 and epsilon=0.2:

Learn nested boolean function with perceptron update rule:
    1. On boolean distribution data
        a. relu as activation function
            Result:
                Total Error : 28
                Average Error : 0.112
                Epsilon :  0.2
                TRAINING SUCCEEDED
        b. tanh as activation function
            Result:
                Total Error : 0
                Average Error : 0.0
                Epsilon :  0.2
                TRAINING SUCCEEDED
        c. threshold as activation function
            Result:
                Total Error : 52
                Average Error : 0.208
                Epsilon :  0.2
                TRAINING FAILED

            Note: When you increase the num_train=750, the error rate dropped.
                Total Error : 42
                Average Error : 0.168
                Epsilon :  0.2
                TRAINING SUCCEEDED

Learn linear threshold function with perceptron update rule:
    1. On boolean distribution data
        a. relu as activation function
            Result:
                Total Error : 0
                Average Error : 0.0
                Epsilon :  0.2
                TRAINING SUCCEEDED
        b. tanh as activation function
            Result:
                Total Error : 0
                Average Error : 0.0
                Epsilon :  0.2
                TRAINING SUCCEEDED
        c. threshold as activation function
            Result:
                Total Error : 89
                Average Error : 0.356
                Epsilon :  0.2
                TRAINING FAILED

            Note : Conducted experiments with different input and output sizes. Still the average error
            rate is nearly the same.

    2. On unit spherical distribution data
        a. relu as activation function
            Result:
                Total Error : 47
                Average Error : 0.188
                Epsilon :  0.2
                TRAINING SUCCEEDED
        b. tanh as activation function
            Result:
                Total Error : 14
                Average Error : 0.056
                Epsilon :  0.2
                TRAINING SUCCEEDED
        c. threshold as activation function
            Result:
                Total Error : 16
                Average Error : 0.064
                Epsilon :  0.2
                TRAINING SUCCEEDED


Comments:
The Perceptron rule was not able to PAC-Learn linear threshold functions under uniform boolean distribution.
They thus match with the PAC learning results learnt from class